@inproceedings{fuzz_recovery,
author = {de Jonge, Maartje and Visser, Eelco},
title = {Automated evaluation of syntax error recovery},
year = {2012},
isbn = {9781450312042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2351676.2351736},
doi = {10.1145/2351676.2351736},
abstract = {Evaluation of parse error recovery techniques is an open problem. The community lacks objective standards and methods to measure the quality of recovery results. This paper proposes an automated technique for recovery evaluation that offers a solution for two main problems in this area. First, a representative testset is generated by a mutation based fuzzing technique that applies knowledge about common syntax errors. Secondly, the quality of the recovery results is automatically measured using an oracle-based evaluation technique. We evaluate the validity of our approach by comparing results obtained by automated evaluation with results obtained by manual inspection. The evaluation shows a clear correspondence between our quality metric and human judgement.},
booktitle = {Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering},
pages = {322–325},
numpages = {4},
keywords = {Test Generation, Parsing, IDE, Evaluation, Error Recovery},
location = {Essen, Germany},
series = {ASE '12}
},
@InProceedings{panic,
  author =	{Diekmann, Lukas and Tratt, Laurence},
  title =	{{Don't Panic! Better, Fewer, Syntax Errors for LR Parsers}},
  booktitle =	{34th European Conference on Object-Oriented Programming (ECOOP 2020)},
  pages =	{6:1--6:32},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-154-2},
  ISSN =	{1868-8969},
  year =	{2020},
  volume =	{166},
  editor =	{Hirschfeld, Robert and Pape, Tobias},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ECOOP.2020.6},
  URN =		{urn:nbn:de:0030-drops-131630},
  doi =		{10.4230/LIPIcs.ECOOP.2020.6},
  annote =	{Keywords: Parsing, error recovery, programming languages}
},

@article{natural_recovery,
author = {de Jonge, Maartje and Kats, Lennart C. L. and Visser, Eelco and S\"{o}derberg, Emma},
title = {Natural and Flexible Error Recovery for Generated Modular Language Environments},
year = {2012},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {4},
issn = {0164-0925},
url = {https://doi.org/10.1145/2400676.2400678},
doi = {10.1145/2400676.2400678},
abstract = {Integrated Development Environments (IDEs) increase programmer productivity, providing rapid, interactive feedback based on the syntax and semantics of a language. Unlike conventional parsing algorithms, scannerless generalized-LR parsing supports the full set of context-free grammars, which is closed under composition, and hence can parse languages composed from separate grammar modules. To apply this algorithm in an interactive environment, this article introduces a novel error recovery mechanism. Our approach is language independent, and relies on automatic derivation of recovery rules from grammars. By taking layout information into consideration it can efficiently suggest natural recovery suggestions.},
journal = {ACM Trans. Program. Lang. Syst.},
month = dec,
articleno = {15},
numpages = {50},
keywords = {generalized parsing, Error recovery}
},
@book{bench,
  author       = {Andrey Akinshin},
  title        = {Pro .NET Benchmarking},
publisher = {Apress Berkeley, CA},
    year = {2019},
},
@inproceedings{forward-move,
author = {Pennello, Thomas J. and DeRemer, Frank},
title = {A forward move algorithm for LR error recovery},
year = {1978},
isbn = {9781450373487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/512760.512786},
doi = {10.1145/512760.512786},
abstract = {A "forward move algorithm", and some of its formal properties, is presented for use in a practical syntactic error recovery scheme for LR parsers. The algorithm finds "valid fragment" (comparable to a valid prefix) just to the right of a point of error detection. For expositional purposes the algorithm is presented as parsing arbitrarily far beyond the point of error detection in a "parallel" mode, as long as all parses agree on the read or reduce action to be taken at each parse step. In practice the forward move is achieved serially by adding "recovery states" to the LR machine. Based on the formal properties of the forward move we propose an error recovery algorithm that uses the accumulated right context. The performance of the recovery algorithm is illustrated in a specific case and discussed in general.},
booktitle = {Proceedings of the 5th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
pages = {241–254},
numpages = {14},
keywords = {syntax errors, parsing, error recovery, SLR (k), LR (k), LALR (k)},
location = {Tucson, Arizona},
series = {POPL '78}
},
@article{10.1145/1993316.1993548,
author = {Parr, Terence and Fisher, Kathleen},
title = {LL(*): the foundation of the ANTLR parser generator},
year = {2011},
issue_date = {June 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/1993316.1993548},
doi = {10.1145/1993316.1993548},
abstract = {Despite the power of Parser Expression Grammars (PEGs) and GLR, parsing is not a solved problem. Adding nondeterminism (parser speculation) to traditional LL and LR parsers can lead to unexpected parse-time behavior and introduces practical issues with error handling, single-step debugging, and side-effecting embedded grammar actions. This paper introduces the LL(*) parsing strategy and an associated grammar analysis algorithm that constructs LL(*) parsing decisions from ANTLR grammars. At parse-time, decisions gracefully throttle up from conventional fixed k&gt;=1 lookahead to arbitrary lookahead and, finally, fail over to backtracking depending on the complexity of the parsing decision and the input symbols. LL(*) parsing strength reaches into the context-sensitive languages, in some cases beyond what GLR and PEGs can express. By statically removing as much speculation as possible, LL(*) provides the expressivity of PEGs while retaining LL's good error handling and unrestricted grammar actions. Widespread use of ANTLR (over 70,000 downloads/year) shows that it is effective for a wide variety of applications.},
journal = {SIGPLAN Not.},
month = jun,
pages = {425–436},
numpages = {12},
keywords = {syntactic predicates, subset construction, semantic predicates, peg, nondeterministic parsing, memoization, glr, deterministic finite automata, context-sensitive parsing, backtracking, augmented transition networks}
}

@inproceedings{all-star,
author = {Parr, Terence and Fisher, Kathleen},
title = {LL(*): the foundation of the ANTLR parser generator},
year = {2011},
isbn = {9781450306638},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1993498.1993548},
doi = {10.1145/1993498.1993548},
abstract = {Despite the power of Parser Expression Grammars (PEGs) and GLR, parsing is not a solved problem. Adding nondeterminism (parser speculation) to traditional LL and LR parsers can lead to unexpected parse-time behavior and introduces practical issues with error handling, single-step debugging, and side-effecting embedded grammar actions. This paper introduces the LL(*) parsing strategy and an associated grammar analysis algorithm that constructs LL(*) parsing decisions from ANTLR grammars. At parse-time, decisions gracefully throttle up from conventional fixed k&gt;=1 lookahead to arbitrary lookahead and, finally, fail over to backtracking depending on the complexity of the parsing decision and the input symbols. LL(*) parsing strength reaches into the context-sensitive languages, in some cases beyond what GLR and PEGs can express. By statically removing as much speculation as possible, LL(*) provides the expressivity of PEGs while retaining LL's good error handling and unrestricted grammar actions. Widespread use of ANTLR (over 70,000 downloads/year) shows that it is effective for a wide variety of applications.},
booktitle = {Proceedings of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {425–436},
numpages = {12},
keywords = {syntactic predicates, subset construction, semantic predicates, peg, nondeterministic parsing, memoization, glr, deterministic finite automata, context-sensitive parsing, backtracking, augmented transition networks},
location = {San Jose, California, USA},
series = {PLDI '11}
},
@INPROCEEDINGS{ai_recovery,
  author={Santos, Eddie Antonio and Campbell, Joshua Charles and Patel, Dhvani and Hindle, Abram and Amaral, José Nelson},
  booktitle={2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={Syntax and sensibility: Using language models to detect and correct syntax errors}, 
  year={2018},
  volume={},
  number={},
  pages={311-322},
  keywords={Syntactics;Java;Machine learning;Tools;Recurrent neural networks;Semantics},
  doi={10.1109/SANER.2018.8330219}},
@inproceedings{blackbox,
author = {Brown, Neil Christopher Charles and K\"{o}lling, Michael and McCall, Davin and Utting, Ian},
title = {Blackbox: a large scale repository of novice programmers' activity},
year = {2014},
isbn = {9781450326056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2538862.2538924},
doi = {10.1145/2538862.2538924},
abstract = {Automatically observing and recording the programming behaviour of novices is an established computing education research technique. However, prior studies have been conducted at a single institution on a small or medium scale, without the possibility of data re-use. Now, the widespread availability of always-on Internet access allows for data collection at a much larger, global scale. In this paper we report on the Blackbox project, begun in June 2013. Blackbox is a perpetual data collection project that collects data from worldwide users of the BlueJ IDE -- a programming environment designed for novice programmers. Over one hundred thousand users have already opted-in to Blackbox. The collected data is anonymous and is available to other researchers for use in their own studies, thus benefitting the larger research community. In this paper, we describe the data available via Blackbox, show some examples of analyses that can be performed using the collected data, and discuss some of the analysis challenges that lie ahead.},
booktitle = {Proceedings of the 45th ACM Technical Symposium on Computer Science Education},
pages = {223–228},
numpages = {6},
keywords = {BlueJ, blackbox, data collection, programming education},
location = {Atlanta, Georgia, USA},
series = {SIGCSE '14}
},
@inproceedings{ide-errors,
author = {Karvelas, Ioannis and Dillane, Joe and Becker, Brett A.},
title = {Programmers' Views on IDE Compilation Mechanisms},
year = {2023},
isbn = {9798400700484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576882.3617915},
doi = {10.1145/3576882.3617915},
abstract = {In this work we investigate the views of novice programmers on three important IDE mechanisms: compilation, error indication, and error message presentation. We utilize two versions of the BlueJ pedagogical programming environment which encapsulate fundamentally different approaches to these mechanisms. This allows us to examine how effective different means of invoking these mechanisms are for novices. We conducted a survey with 305 programmers with different levels of experience who provided rating scores for the individual mechanisms mentioned. Additionally, participants provided suggestions on how these features should be facilitated to assist novices. The present findings serve as evidence regarding the effectiveness and usability of different mechanisms featured within programming environments. These findings can assist designers of pedagogical programming environments in making evidence-based decisions about their products and facilitate the development of environments that can achieve greater efficacy for novices in their first steps of learning.},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 1},
pages = {98–104},
numpages = {7},
keywords = {BlueJ, CS1, IDE, compilation, compiler error messages, novice programmers, programming, programming behavior, programming environments, programming error messages},
location = {Hyderabad, India},
series = {CompEd 2023}
},
@INPROCEEDINGS{clf-recovery,
  author={Zhang, Wenjie and Wang, Guancheng and Chen, Junjie and Xiong, Yingfei and Liu, Yong and Zhang, Lu},
  booktitle={2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={OrdinalFix: Fixing Compilation Errors via Shortest-Path CFL Reachability}, 
  year={2023},
  volume={},
  number={},
  pages={1200-1211},
  keywords={Java;Software algorithms;Syntactics;Software;Time complexity;Task analysis;Software engineering;Compilation Error;CFL Reachability},
  doi={10.1109/ASE56229.2023.00072}},
@article{peg-recovery,
author = {Queiroz de Medeiros, S\'{e}rgio and de Azevedo Alvez Junior, Gilney and Mascarenhas, Fabio},
title = {Automatic syntax error reporting and recovery in parsing expression grammars},
year = {2020},
issue_date = {Feb 2020},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {187},
number = {C},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2019.102373},
doi = {10.1016/j.scico.2019.102373},
journal = {Sci. Comput. Program.},
month = feb,
numpages = {22},
keywords = {Error recovery, Error reporting, Labeled failures, Parsing expression grammars}
},
@article{seq2parse,
author = {Sakkas, Georgios and Endres, Madeline and Guo, Philip J. and Weimer, Westley and Jhala, Ranjit},
title = {Seq2Parse: neurosymbolic parse error repair},
year = {2022},
issue_date = {October 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3563330},
doi = {10.1145/3563330},
abstract = {We present Seq2Parse, a language-agnostic neurosymbolic approach to automatically repairing parse errors. Seq2Parse is based on the insight that Symbolic Error Correcting (EC) Parsers can, in principle, synthesize repairs, but, in practice, are overwhelmed by the many error-correction rules that are not relevant to the particular program that requires repair. In contrast, Neural approaches are fooled by the large space of possible sequence level edits, but can precisely pinpoint the set of EC-rules that are relevant to a particular program. We show how to combine their complementary strengths by using neural methods to train a sequence classifier that predicts the small set of relevant EC-rules for an ill-parsed program, after which, the symbolic EC-parsing algorithm can make short work of generating useful repairs. We train and evaluate our method on a dataset of 1,100,000 Python programs, and show that Seq2Parse is accurate and efficient: it can parse 94\% of our tests within 2.1 seconds, while generating the exact user fix in 1 out 3 of the cases; and useful: humans perceive both Seq2Parse-generated error locations and repairs to be almost as good as human-generated ones in a statistically-significant manner.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {167},
numpages = {27},
keywords = {Machine Learning, Error-Correcting Parsers, Automated Program Repair}
},
@INPROCEEDINGS{symbolic,
  author={Koo, Jinkyu and Saumya, Charitha and Kulkarni, Milind and Bagchi, Saurabh},
  booktitle={2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST)}, 
  title={PySE: Automatic Worst-Case Test Generation by Reinforcement Learning}, 
  year={2019},
  volume={},
  number={},
  pages={136-147},
  keywords={Complexity theory;Testing;Explosions;Stress;Python;History;Genetic algorithms;Machine learning;Q-learning;Symbolic execution;Worst-case complexity;Stress testing},
  doi={10.1109/ICST.2019.00023}},

@inproceedings{towards-recovery,
author = {de Medeiros, S\'{e}rgio Queiroz and Mascarenhas, Fabio},
title = {Towards automatic error recovery in parsing expression grammars},
year = {2018},
isbn = {9781450364805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3264637.3264638},
doi = {10.1145/3264637.3264638},
abstract = {Error recovery is an essential feature for a parser that should be plugged in Integrated Development Environments (IDEs), which must build Abstract Syntax Trees (ASTs) even for syntactically invalid programs in order to offer features such as automated refactoring and code completion.Parsing Expressions Grammars (PEGs) are a formalism that naturally describes recursive top-down parsers using a restricted form of backtracking. Labeled failures are a conservative extension of PEGs that adds an error reporting mechanism for PEG parsers, and these labels can also be associated with recovery expressions to also be an error recovery mechanism. These expressions can use the full expressivity of PEGs to recover from syntactic errors.Manually annotating a large grammar with labels and recovery expressions can be difficult. In this work, we present an algorithm that automatically annotates a PEG with labels, and builds their corresponding recovery expressions. We evaluate this algorithm by adding error recovery to the parser of the Titan programming language. The results shown that with a small amount of manual intervention our algorithm can be used to produce error recovering parsers for PEGs where most of the alternatives are disjoint.},
booktitle = {Proceedings of the XXII Brazilian Symposium on Programming Languages},
pages = {3–10},
numpages = {8},
keywords = {parsing expression grammars, parsing, error recovery},
location = {Sao Carlos, Brazil},
series = {SBLP '18}
},
@inproceedings{error-frequence,
author = {Pritchard, David},
title = {Frequency distribution of error messages},
year = {2015},
isbn = {9781450339070},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2846680.2846681},
doi = {10.1145/2846680.2846681},
abstract = {Which programming error messages are the most common? We investigate this question, motivated by writing error explanations for novices. We consider large data sets in Python and Java that include both syntax and run-time errors. In both data sets, after grouping essentially identical messages, the error message frequencies empirically resemble Zipf-Mandelbrot distributions. We use a maximum-likelihood approach to fit the distribution parameters. This gives one possible way to contrast languages or compilers quantitatively.},
booktitle = {Proceedings of the 6th Workshop on Evaluation and Usability of Programming Languages and Tools},
pages = {1–8},
numpages = {8},
keywords = {usability, empirical analysis, education, Error messages},
location = {Pittsburgh, PA, USA},
series = {PLATEAU 2015}
},
@inproceedings{bluej,
author = {Utting, Ian and Brown, Neil and K\"{o}lling, Michael and McCall, Davin and Stevens, Philip},
title = {Web-scale data gathering with BlueJ},
year = {2012},
isbn = {9781450316040},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2361276.2361278},
doi = {10.1145/2361276.2361278},
abstract = {Many investigations of students' initial learning of programming are based on small-scale studies of their interactions with a learning environment. Although this research has led to significant improvements in the understanding of student behaviour (and tool support), it has often been restricted to small numbers of students at single institutions. This paper describes an initiative to instrument the widely-used BlueJ environment to collect data on a much larger scale, and make that data available to Computing Education researchers. The availability of this data has the potential to enable research not previously possible. This paper discusses the type of data that will be gathered, the restrictions placed on identifying students, and mechanisms for associating the data with contextual data gathered outside the scope of the initiative.},
booktitle = {Proceedings of the Ninth Annual International Conference on International Computing Education Research},
pages = {1–4},
numpages = {4},
keywords = {student behaviour, initial programming, data collection, cs1, bluej},
location = {Auckland, New Zealand},
series = {ICER '12}
},
@inproceedings{first-errors,
author = {Becker, Brett A. and Murray, Cormac and Tao, Tianyi and Song, Changheng and McCartney, Robert and Sanders, Kate},
title = {Fix the First, Ignore the Rest: Dealing with Multiple Compiler Error Messages},
year = {2018},
isbn = {9781450351034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3159450.3159453},
doi = {10.1145/3159450.3159453},
abstract = {In order to help students learning to develop computer programs, several computing education researchers have analyzed the compiler error messages generated by novices' attempts to compile their programs. The goal is to help students diagnose the errors they make through the messages generated by the compiler. This paper builds on that previous work by applying a technique based on a heuristic well-known to programmers - fix the first error and ignore the rest - to the analysis of over 21 million compiler error messages from the Blackbox dataset. We find that the ranks and frequencies obtained by considering all error messages are generally consistent with previously published lists, but when we consider first messages only, these ranks and frequencies are different. These differences could have important implications for teaching, and can inform tool design and future research efforts.},
booktitle = {Proceedings of the 49th ACM Technical Symposium on Computer Science Education},
pages = {634–639},
numpages = {6},
keywords = {CS1, blackbox, buried error messages, cascading error messages, compiler error messages, debugging, novice programmers, novice syntax errors, subsequent error messages},
location = {Baltimore, Maryland, USA},
series = {SIGCSE '18}
},
@inproceedings{error-measures-3,
author = {\v{S}v\'{a}bensk\'{y}, Valdemar and Pankiewicz, Maciej and Zhang, Jiayi and Cloude, Elizabeth B. and Baker, Ryan S. and Fouh, Eric},
title = {Comparison of Three Programming Error Measures for Explaining Variability in CS1 Grades},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653563},
doi = {10.1145/3649217.3653563},
abstract = {Programming courses can be challenging for first year university students, especially for those without prior coding experience. Students initially struggle with code syntax, but as more advanced topics are introduced across a semester, the difficulty in learning to program shifts to learning computational thinking (e.g., debugging strategies). This study examined the relationships between students' rate of programming errors and their grades on two exams. Using an online integrated development environment, data were collected from 280 students in a Java programming course. The course had two parts. The first focused on introductory procedural programming and culminated with exam 1, while the second part covered more complex topics and object-oriented programming and ended with exam 2. To measure students' programming abilities, 51095 code snapshots were collected from students while they completed assignments that were autograded based on unit tests. Compiler and runtime errors were extracted from the snapshots, and three measures - Error Count, Error Quotient and Repeated Error Density - were explored to identify the best measure explaining variability in exam grades. Models utilizing Error Quotient outperformed the models using the other two measures, in terms of the explained variability in grades and Bayesian Information Criterion. Compiler errors were significant predictors of exam 1 grades but not exam 2 grades; only runtime errors significantly predicted exam 2 grades. The findings indicate that leveraging Error Quotient with multiple error types (compiler and runtime) may be a better measure of students' introductory programming abilities, though still not explaining most of the observed variability.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {87–93},
numpages = {7},
keywords = {computer science education, introduction to programming, introductory programming, novice programming, programming education},
location = {Milan, Italy},
series = {ITiCSE 2024}
},
@article{recovery-types,
author = {Degano, Pierpaolo and Priami, Corrado},
title = {Comparison of syntactic error handling in LR parsers},
year = {1995},
issue_date = {June 1995},
publisher = {John Wiley \& Sons, Inc.},
address = {USA},
volume = {25},
number = {6},
issn = {0038-0644},
url = {https://doi.org/10.1002/spe.4380250606},
doi = {10.1002/spe.4380250606},
journal = {Softw. Pract. Exper.},
month = jun,
pages = {657–679},
numpages = {23},
keywords = {LR parsers, compilers, context-free grammars, error detection, repair and correction, syntactic errors}
},
@inproceedings{ai-c-recovery,
author = {Gupta, Rahul and Kanade, Aditya and Shevade, Shirish},
title = {Deep reinforcement learning for syntactic error repair in student programs},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v33i01.3301930},
doi = {10.1609/aaai.v33i01.3301930},
abstract = {Novice programmers often struggle with the formal syntax of programming languages. In the traditional classroom setting, they can make progress with the help of real time feedback from their instructors which is often impossible to get in the massive open online course (MOOC) setting. Syntactic error repair techniques have huge potential to assist them at scale. Towards this, we design a novel programming language correction framework amenable to reinforcement learning. The framework allows an agent to mimic human actions for text navigation and editing. We demonstrate that the agent can be trained through self-exploration directly from the raw input, that is, program text itself, without either supervision or any prior knowledge of the formal syntax of the programming language. We evaluate our technique on a publicly available dataset containing 6975 erroneous C programs with typographic errors, written by students during an introductory programming course. Our technique fxes 1699 (24.4\%) programs completely and 1310 (18.8\%) program partially, outperforming DeepFix, a state-of-the-art syntactic error repair technique, which uses a fully supervised neural machine translation approach.},
booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {115},
numpages = {8},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
},
@article{editing-distance,
author = {Medvedev, Paul},
title = {Theoretical Analysis of Edit Distance Algorithms},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {66},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/3582490},
doi = {10.1145/3582490},
abstract = {To what extent have the techniques for theoretical analysis of edit distance algorithms achieved their goals?},
journal = {Commun. ACM},
month = nov,
pages = {64–71},
numpages = {8}
},
@article{ai-recovery-large,
author = {Zhou, Xin and Cao, Sicong and Sun, Xiaobing and Lo, David},
title = {Large Language Model for Vulnerability Detection and Repair: Literature Review and the Road Ahead},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708522},
doi = {10.1145/3708522},
abstract = {The significant advancements in Large Language Models (LLMs) have resulted in their widespread adoption across various tasks within Software Engineering (SE), including vulnerability detection and repair. Numerous studies have investigated the application of LLMs to enhance vulnerability detection and repair tasks. Despite the increasing research interest, there is currently no existing survey that focuses on the utilization of LLMs for vulnerability detection and repair. In this paper, we aim to bridge this gap by offering a systematic literature review of approaches aimed at improving vulnerability detection and repair through the utilization of LLMs. The review encompasses research work from leading SE, AI, and Security conferences and journals, encompassing 43 papers published across 25 distinct venues, along with 15 high-quality preprint papers, bringing the total to 58 papers. By answering three key research questions, we aim to (1) summarize the LLMs employed in the relevant literature, (2) categorize various LLM adaptation techniques in vulnerability detection, and (3) classify various LLM adaptation techniques in vulnerability repair. Based on our findings, we have identified a series of limitations of existing studies. Additionally, we have outlined a roadmap highlighting potential opportunities that we believe are pertinent and crucial for future research endeavors.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
keywords = {Literature review, vulnerability detection, vulnerability repair, large language models}
},
@misc{exact-match-ai,
      title={DeepCode AI Fix: Fixing Security Vulnerabilities with Large Language Models}, 
      author={Berkay Berabi and Alexey Gronskiy and Veselin Raychev and Gishor Sivanrupan and Victor Chibotaru and Martin Vechev},
      year={2024},
      eprint={2402.13291},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2402.13291}, 
}